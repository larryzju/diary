* Concepts
** Landscape
** TODO Region and Zone

** Global Infrastructure

分为三个主题: region, zone, edge location

*** region

降低成本，减小延迟，数据保护。不同的 region 中可能提供的服务略有不同

*** availability zone

数据中心，同一个 region 内有多个独立的 zone，物理上独立，通过低速网络连接。
不会受其它 zone 故障影响。

建议跨 zone 部署应用和数据

*** edge clocatoin

CloudFront 提供类似 CDN 功能，自动将请求改善到优化的、可用的站点

** Security Group

通过配置安全规则 ，允许或禁止流量：私有、公有、混合

Management Console 中选择 EC2，在 Security Group Tab 进行配置
例如，创建一个 web-server-sg 组，选择相应的 VPC，配置 inbound 规则，允许 0.0.0.0/0 TCP 80/443 流量

* Command Line

** 配置文件

有两个 

1. =~/.aws/config=

   ini 语法，默认是 default section，可以定义 =[profile profile-name]= section，保存 region, access id, secret access key

2. =~/.aws/credential=

   ini 语法，按 config 中的 profile 来分 section，用来保存 access key id, secret access key, session token

** 指定 credential 

1. 命令行
2. 环境变化
3. credential file
4. config file

*** 环境变量

- =AWS_ACCESS_KEY_ID=
- =AWS_SECRET_ACCESS_KEY=

** bash complete

参见 https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-completion.html

#+BEGIN_SRC 
complete -C $(which aws_completer) aws
#+END_SRC

* EC2

Elastic Compute Cloud：云服务器。称为 EC2 实例

- 按实际使用量付费
- 软件/硬件选项
- 多 region 区域

** Term

- AMI :: Amazon Machine Image, pre-configured server templates to launch an instance

** steps to create EC2 instance

1. choose region
2. choose AMI (OS Image)
3. choose an instance type: cpu, memory, cores
4. configure instance details
5. add storage (volume)
6. add tags (friendly name)
7. configure security group (firewall rules)
8. review and launch, download key pair for future SSH usage


** access the instance

1. get the public DNS or public IP address from AWS management console
2. add private key to putty auth configuration (convert from PEM to PPK format before login with *PuttyGen*)
3. login with the default user name =ec2-user= 

* EBS

提供 EC2 的存储空间，可以是硬盘，也可以是 SSD。有自己的生命周期，可以不随 EC2 删除而删除

可以生成快照，并复制到不同的 zone 和 region，并从快照中恢复。存储内容可以被自动加密

** steps to create and use ebs volume

1. create volume: specify availability zone, volume type, size
2. attach volume to instance and set the device path (such as /dev/sdb)
3. login in linux, check with =lsblk= command line
4. format disk: =mkfs.ext4 /dev/xvdb=
5. mount partition to mountpoint =mount /dev/xvdb /mnt=

* S3

Amazon Simple Storage Service 的缩写，提供对象存储，可以为传输过程加密，设置不同的访问权限。提供容灾备份，可以作为大数据的数据x存放

EC2 中可以使用 aws 命令直接访相关 bucket（不像 EBS 被挂载到文件系统）

** terms

- object :: An *object* consists of a file and optionally any metadata
            that describes that file. (like inode with data)

- bucket :: objects' container, associate with region, have duplicas, control access

** basic usage steps

1. sign up for S3
2. create a bucket: specify unique name and region
3. add an object to bucket
4. you can view information about the object and download the object to local computer
5. create a folder and copy the object into the new folder
6. delete object, or empty bucket - delete all objects in the bucket, or delete a bucket

** Command Line

Refer to =aws s3 help= page

*** Pattern Match

No support for UNIX style wildcards in path arguments. Use =--exclude=
or =--include= paramters instead.

The order is important
| command                           | description                                         |
|-----------------------------------+-----------------------------------------------------|
| ~--exclude "*" --include "*.txt"~ | exclude all files except for files ending with .txt |
| ~--include "*.txt" --exclude "*"~ | exclude all files                                   |

If the source target is a file, then the source directory will be used for pattern match

*** TODO Prefix

*** Path Type

- LocalPath :: absolute path or relative path
- S3Uri :: location of a S3 object, prefix, or bucket. For example =s3://mybucket/mykey=

*** Commands

| command | description                                                                             |
|---------+-----------------------------------------------------------------------------------------|
| ls      | =aws s3 ls s3://mybucket=                                                               |
| cp      | =aws s3 cp ~/cities.csv s3://mybucket=                                                  |
| mv      | =aws s3 mv s3://mybucket/cities.csv s3://mybucket/cities2.csv=                          |
| rm      | =aws s3 rm s3://mybucket/cities2.csv=                                                   |
| sync    | recursively copies new and updated files from src to dst                                |
| mb      | make bucket                                                                             |
| rb      | remove bucket                                                                           |
| website | generate a static website, =aws s3 website s3://my-bucket/ --index-document index.html= |
| presign | Generate a pre-signed URL for S3 object                                                 |

*** TODO ACL

** Issue

*** OptionsRequestDenied

Refer to https://aws.amazon.com/premiumsupport/knowledge-center/s3-optionsrequestdenied-error/

It seems a client-side error
- blocked by the web browser extension
- blocked by proxies or firewalls
- intermittent network connection problem 

Try uploading files using AWS CLI command instead.

** How To
*** Get the website URL

* VPC

Virtual Private Cloud is a virtual networking layer for Amazon EC2
that enable you to launch AWS resources into a virtual network.

主要功能包括：隔离网络，访问控制，定义路由规则

针对 region，跨多个 availability zone。定义一个 IP 范围，可以包括多个子网。
子网包括公有和私有两种，公网包括公有 IP 地址。

By default, there's already a default VPC for your instances. And we
can create our own VPC and subnets.

Feature of EC2-VPC:
- static and persisted private IPv4 addresses to instance
- optionally associated an IPv6 CIDE block to VPC
- optionally assign IPv6 address to instance
- define multiple network interfaces to your instance
- manage security group membership
- egress/ingress filtering
- ACL
- run your instance on single-tenant hardware (?)

VPC information
- subnet
- internet gateway
- route table
  + main route table (by default)
  + custom route table


** Steps to set up VPC

1. choose a region
2. create VPC: name, IP address range (10.0.0.0/16)
3. create subnet: name, ip address range (10.0.0.0/24), zone
4. add internet gateway: to access the internet

** Key Concept

- isolate from other virtual network
  - IP address range
  - subnets
    + public subnet that can connect to the internet
    + private subnet for resources that won't be connected to the internet
  - security groups
  - configure route tables

** Architecture

*** Default VPC

#+CAPTION
[[./images/default-vpc-diagram.png]]
VPC may span multiple zones and there's a separated subnet in each zone.

Each instance that launch into a default subnet has
- a private IPv4 address
- a public IPv4 address

These instances can communicate with the internet through the internet gateway.

*** Nondefault VPC

#+CAPTION: Nondefault VPC Diagram
[[./images/nondefault-vpc-diagram.png]]

- Only private IPv4 addresses are assigned
- instances can communicate with each other (even across the subnets)
- there's no internet gateway been attached to this VPC

**** Enable internet access

#+CAPTION: Internet gateway Diagram
[[./images/internet-gateway-diagram.png]]

1. Attach an internet gateway to this VPC
2. associate an Elastic IP to the instance


**** NAT

For the scenario that to allow outbound traffic only by 
- create a NAT device (has an Elastic IP address and connects to the internet through an internet gateway)
- and map multiple private IPv4 addresses to single IPv4 address


**** TODO IPv6

**** TODO VPN

**** TODO PrivateLink

** Different from traditional network
** TODO VPC Endpoints
** TODO DNS
** TODO Hardware tenancy
** TODO Security Group

Acts as a virtual firewall to control the traffic for its associated instances.

Rules contains:
- inbound rules
- outbound rules

Associate a security group with an instance when launching the instance.

There's a default security group

*** inbound rules

IP + Protocol + Port Range + Comments

- public IPv4 address range of your home network


- Type
  - Protocol
  - Port Range
- Source
  - Custom
  - Anywhere
  - My IP
- Description

*** outbound rules

** VPC Peering 
** How to

*** check the internet gateway info of VPC

*** display the main route table rules 

*** get the custom route table info of VPC

- local route, allow instances to communicate with each other
- outside flow

*** check the default security group

*** get the subnet info of VPC

*** describe VPCs

#+BEGIN_SRC bash
aws ec2 describe-vpcs
#+END_SRC

Return list of VPC configurations
- CIDR block
- DHCP options set
- Tenancy: if allow tenancy of instances launched into the VPC
- is default
- Owner ID: Aws account

*** expose service inside a non-default VPC

1. create a VPC (specify CIDR)
2. attach an internet gateway
3. create subnet (specify subnet's CIDR)
4. create a custom route table and associate it with the subnet

*** launch an instance
*** assign an elastic IP address to your instance

- specify the subnet

**** TODO AMI
** Reference

- [[https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html][What is Amazon VPC]]
- [[https://docs.aws.amazon.com/vpc/latest/userguide/getting-started-ipv4.html][getting started with IPv4]]

* ECS

Elastic Container Service is the service to run Docker application on a scalable cluster.

* EKS

EKS is short for Elastic Kubernetes Service which is a logical
grouping of EC2 compute instances that run your containers. EKS works
as a managed service that makes it easy for you to use Kubernetes on
AWS without needing to install and operate the Kubernetes control plane.

A cluster consists of the _control plane_ and the _data plane_.

There're two types of instances:
- master ::  host the Kubernetes API server and control how, when, and where your container run
- worker :: compute instance where your containers actually run and process data

Pod is the basic component of the Kubernetes which includes containers
and specifications for how they should run, networking, and storage.

=etcd= is a distributed key value store that lets you store and share
data across a distributed cluster of machines. K8s's control plane
data is stored in =etcd=.

** TODO What is 

*** control plane

*** node group

*** IAM identity mapping

*** security group

** Steps to deploy

1. Provision and EKS cluster
2. Amazon EC2
3. Connect to EKS

** create cluster with eksctl

Refer to https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html

*** prerequisites

**** install awscli

#+BEGIN_SRC bash
pip install awscli --upgrade --user
#+END_SRC

**** configure awscli credential

Login with access key, secret access key, AWS region, and output
format. This information is stored in a profile named /default/.

#+BEGIN_SRC bash
aws configure
#+END_SRC

**** install eksctl

#+BEGIN_SRC bash
curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
mv /tmp/eksctl ~/.local/bin
eksctl version
#+END_SRC

**** install kubectl
skip


*** create EKS cluster and worker nodes

**** create

#+BEGIN_SRC bash
eksctl create cluster \
  --name larry-testing \
  --version 1.13 \
  --nodegroup-name standard-workers \
  --node-type t3.medium \
  --nodes 2 \
  --nodes-min 1 \
  --nodes-max 3 \
  --node-ami auto
#+END_SRC

**** verify

#+BEGIN_SRC bash
kubectl get svc
#+END_SRC

** create cluster with AWS Management Console

*** Prerequisites

Prerequisites contain
- create an IAM role that k8s can assume to create AWS resources, such as Elastic Load balancing
- create a VPC and security group

**** create EKS service role in the IAM console

1. select AWS service, EKS use case
2. skip permission step, choose *Next: Tags*
3. (optional) add metadata to the role by attaching tags
4. review and assign a unique name for your role
5. create role

**** create EKS Cluster VPC

1. goto [[https://console.aws.amazon.com/cloudformation][CloudFormation console]]
2. select region and create stack
3. use the Amazon S3 URL template source
4. fill in URL =https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-02-11/amazon-eks-vpc-private-subnets.yaml=
5. fill out the parameters
   + Stack name: unique name
   + VpcBlock: CIDR range for your VPC
   + PublicSubnet01Block: CIDR range for public subnet1
   + PublicSubnet02Block: CIDR range for public subnet2
   + PrivateSubnet01Block: CIDR range for private subnet1
   + PrivateSubnet02Block: CIDR range for private subnet2
6. (optional) tag your stack resources
7. review and create
8. select the stack that is created and record the *SecurityGroups* value in the *Outputs*
9. record *VpcId* for the VPC that was created
10. record the *SubnetIds* for the subnets that were created
11. Tag your private subnets so the k8s knows that it can use them for internal load balancers
    1. goto [[https://console.aws.amazon.com/vpc/][VPC console]] and choose *Subnets*
    2. select the two private subnets and create new tag =kubernetes.io/role/inernal-elb= with value =1=


***** SecurityGroups

Apply to the cross-account elastic network interfaces that are created
in your subnets that allow the Amazon EKS control plane to communicate
with your worker nodes.

***** VpcID

The VPC that worker nodes run on

***** SubnetIds

The subnets that your worker nodes are launched into.

**** install kubectl

skip

**** install awscli

skip


*** create EKS cluster

1. goto [[https://console.aws.amazon.com/eks/home#/clusters][EKS console]]
2. Choose *Create cluster*
3. fill in fields
   + cluster name: uniqune name for your cluster
   + kubernetes version: the version of kubernetes to use for your cluster
   + Role ARN: the IAM role created before
   + VPC
   + Subnets: choose all private/public subnets created before
   + Security groups
   + API server endpoint access: private false
   + Logging
4. choose a cluster name and create


*** create a kubeconfig file

#+BEGIN_SRC bash
aws eks --region <region> update-kubeconfig --name <cluster-name> --kubeconfig <kubeconfig-path>
#+END_SRC

Verify by running =kubectl get svc=


*** launch and configure EKS worker nodes

**** launch worker nodes

1. wait for your cluster status to show as =ACTIVE=
2. go to [[https://console.aws.amazon.com/cloudformation/][CloudFormation console]]
3. create work nodes stack
4. use Amazon S3 template URL and fill the URL =https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-02-11/amazon-eks-nodegroup.yaml=
5. specify details
   - ClusterName must exactly match the name we used for EKS cluster
   - NodeImageId is the AMI ID, for example =ami-07ebcae043cf995aa=
   - KeyName is the EC2 Key Pair Name
   - BootstrapArguments are the extra =kubelet= arguments
6. add tag to the stack resources
7. review and create
8. waiting for the creating has finished
9. select the stack and record *NodeInstanceRole* in the output tab

**** enable worker nodes to join your cluster

1. get the kubeconfig via =awk eks update-kubeconfig= command
2. download configure map yaml configuration
   #+BEGIN_SRC bash
   curl -o aws-auth-cm.yaml https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2019-02-11/aws-auth-cm.yaml
   #+END_SRC
3. update the configure map and replace the =ARN of instance role= with the *NodeInstanceRole*
4. apply the configuration
5. check the nodes with =kubectl get nodes=

** delete cluster

*** remove all service with external IP

#+BEGIN_SRC bash
kubectl get svc --all-namespaces
kubectl delete svc <service-name>
#+END_SRC

*** delete the worker node AWS CloudFormation stack

#+BEGIN_SRC bash
aws cloudformation list-stacks --query StackSummaries[].StackName
aws cloudformation delete-stack --stack-name <worker-node-stack>
#+END_SRC

*** delete the EKS cluster

#+BEGIN_SRC bash
aws eks delete-cluster --name <my-cluster>
#+END_SRC

*** delete the VPC AWS CloudFormation stack

#+BEGIN_SRC bash
aws cloudformation list-stacks --query StackSummaries[].StackName
aws cloudformation delete-stack --stack-name <my-vpc-stack>
#+END_SRC

** Command line

*** aws eks

| command                                                                     | description            |
|-----------------------------------------------------------------------------+------------------------|
| aws eks list-clusters                                                       | list all clusters      |
| aws eks describe-cluster --name <cluster-name>                              | describe cluster       |
| aws eks update-kubeconfig --kubeconfig ~/.kube/output --name <cluster-name> | create kubeconfig file |
| aws eks delete-cluster --name <cluster-name>                                | delete eks cluster     |

*** eksctl

=eksctl= is a =kubectl= style like command line tool.

| command                                 | description          |
|-----------------------------------------+----------------------|
| eksctl get cluster                      | get clusters         |
| eksctl get cluster -n <cluster-name>    | show cluster details |
| eksctl delete cluster -n <cluster-name> | delete a cluster     |

** How To
*** Get the EC2 instance of the cluster

Filter the EC2 instance with VPCId

**** get the EKS clusters's metadata

Describe the cluster and record the VPCId.

#+BEGIN_SRC bash
   aws eks list-clusters
   aws eks describe-cluster --name <cluster-name>
#+END_SRC

**** filter the EC2 instance with VPC id

#+BEGIN_SRC bash
aws ec2 describe-instances --filter Name=network-interface.vpc-id,Values=${VPCID}
#+END_SRC

* KMS

Key Management Service 的缩写，用于创建和管理 CMK (Control Customer Master Keys，用于加密数据）

CMKs 的常规操作包括

- 创建、删除、修改
- 启用、禁用
- 自动 rotation
- alias


** Concepts

- CMKs :: master key with metadata (key ID, date, description, state)
- alias :: identify an associated CMK within an account and region. Can be used as the =key-id= to describe or tag the CMK
- Key identifier :: unique identity for the customer master keys
  1. key arn
  2. key id
  3. alias
  4. alias ARN

** How to 

*** select keys by alias

#+BEGIN_SRC sh
aws kms list-aliases
#+END_SRC

*** describe key

#+BEGIN_SRC sh
aws kms describe-key --key-id e049c24a-8370-4ddb-8233-7bfe7c959190
#+END_SRC


*** list tags 

#+BEGIN_SRC sh
 aws kms list-resource-tags --key-id e049c24a-8370-4ddb-8233-7bfe7c959190
#+END_SRC

* MSK

AWS 管理的 kafka 集群，除了常规的 kafka 数据操作外，AWS 提供了额外的 control-pane 能力，通过 AWS CLI 来管理整个集群。
结构图参见 https://docs.aws.amazon.com/msk/latest/developerguide/what-is-msk.html

注意：
- 每个 zone 都有独立的 VPC，其中包括 EC2 来运行 broker

MSK 监控 broker 健康状态，如果发现异常，则会替换 broker（在同一个 zone?）

** 创建步骤

1. 创建单公共子网 VPC (single public subnet)
2. HA: 创建另外两个子网，使用独立了子网 CIDR （如 10.0.1.0/24 和 10.0.2.0/24），修改 route table association 为子网一的 route table (??)
3. 准备配置文件 clusterinfo.json (指定子网 ID, VPC security group ID, CMK ID，Client 加密方式), 创建 cluster =aws kafka create-cluster --cli-input-json <json-file>=
4. 在同一 VPC 中新建 EC2 实例，并在 VPC secrutiy group 中添加 inboud rule，允许 EC2 对应的 security group 访问
5. 检查 cluster 状态 =aws kafka describe-cluster --region <regon> --cluster-arn <cluster-arn>= ，检查返回的 'State' 字段是否为 'Active'
6. 在 EC2 实例中安装 kafka client，访问 =ZookeeperConnectString= 对应的 kafka 集群，创建 topic
7. 配置 client.properties（加密方式），连接 =BootstrapBrokerStringTLs= （通过 describe-cluster 返回），生产或消息 topic messages
8. 使用 =aws kafka delete-cluster --region <region> --cluster-arn <cluster-arn>= 删除 kafka cluster


* CloudFormation

Declare all of your resoruces and dependencies in a template file to
create and manage AWS infrastructure deployments predictably and
repeatedly.

类似于 helm chart？

It can be used to leverage AWS products
- EC2
- Elastic Block Store
- Simple Notification Service
- Elastic Load Balancing

** What is

*** TODO Stack

** How to

*** get stack template

- Use command =aws cloudformation get-template --stack-name <stack-name>=
- Or check it in cloudformation, stack, template tab page.

** Commands

| command                                                      | description          |
|--------------------------------------------------------------+----------------------|
| aws cloudformation list-stacks                               | list stacks          |
| aws cloudformation describe-stacks --stack-name <stack-name> | describe stack       |
| aws cloudformation get-template --stack-name <stack-name>    | get stack's template |
| aws cloudformation delete-stack --stack-name <stack-name>    | delete a stack       |

* CloudWatch

查看 metrics

* HOWTO

** get current region

#+BEGIN_SRC bash
aws configure --profile default get region
#+END_SRC

** get access key

#+BEGIN_SRC bash
aws configure get aws_access_key_id
#+END_SRC

Or you can get the credential by check files =~/.aws/config= and ~/.aws/credential~

** get IAM access ID

Get access key (without secret access token)
#+BEGIN_SRC sh
aws iam list-access-keys --user-name 'larry.zhao01@sap.com'
#+END_SRC

每个用户最多有两个 access ID，secret access token 仅在创建时返回，之后无法再次获得
 
** rotate access key

每个用户最多有两个 access ID，secret access token 仅在创建时返回，之后无法再次获得

1. 创建新 access key: ~aws iam create-access-key~ ，记录 secret access key
2. 禁用老的 access key: ~aws iam update-access-key --access-key-id access-key --status Inactive~
3. 删除老的 access key: ~aws iam delete-access-key --access-key-id access-key~

** get account ID

#+BEGIN_SRC sh
 aws sts get-caller-identity
#+END_SRC

** show account alias

#+BEGIN_SRC sh
  aws iam list-account-aliases
#+END_SRC

** TODO how to check the policy definition


* IAM

全称是 AWS Identity and Access Management，包括了认证和授权两部分功能

1. authenticate (sign in)
2. authorized (permission control)

Root user/password 有最高的权限，一般不应用于实际生产环境。而是创建其它的 IAM 账户来使用。

AWS Account 可以有（且仅有最多）一个 Alias，这样在登录时可以用 alias 作为 URL 前缀，而不使用数字的 account ID，如 https://Your_Account_Alias.signin.aws.amazon.com/console/


** 使用场景

为不同的客户生成 IAM User，每个 IAM 用户都有自己的权限配置，来限制不同的资源访问



** Terms

| Name      | Description                         |
|-----------+-------------------------------------|
| principal | 使用者，使用 root credential 或 IAM |
| resources | 要访问的 AWS 资源                   |
| identity  | 标识 IAM，如 user, group, role      |


** Policy

需要显式的被授权，默认为禁用

*** Indentity-based policy

*** Resource-based policy

跨不同的 account 访问资源，例如跨 AWS account 访问 ECR

*** TODO user policy, user attached policy, group policy and group attached policy

一个 IAM 账号的权限由多个 policy 来控制

#+BEGIN_SRC sh
aws iam list-user-policies --user-name username
aws iam list-attached-user-policies --user-name username
aws iam list-group-policies --group-name groupname
aws iam list-attached-group-policies --group-name groupname
#+END_SRC



** User, Group, Role

三类

1. root user :: 邮箱名和密码登录, root user 有最高的权限，类似于 linux
                root 用户。不要用于日常生产环境，而是新建 IAM 用户来使
                用。

2. IAM users :: root 账号下的子账号，有独立的密码和权限管理。不一定是
                真正的“人”，也可能分配给某个应用使用

3. Federating users :: 使用外部账户登录，需要与 SSO 或者 IDP 集成



** Permissions, Policies

创建 policy，并将之赋予 IAM identity 或者 AWS resource，进行访问管理 (Access Management）


** identity-based policy

Control what _actions_ the _identity_ can perform, on which _resources_, and under what _conditions_

可以在 user, group, role 嵌入式的指定，也可以创建 policy 并在 user, group, role 中引用之

*** Account

- 对于单账户 (single account) ，可以通过 policy 来管理
- 对于多账户，使用 IAM roles, resource-based policy, ACL 来管理

*** User

创建 identity-based policy ，把 policy 授予 user 或者 group。Policy 以 JSON 描述，包括

| Name     | Description |
|----------+-------------|
| Effect   | Allow/Deny  |
| Action   | dynamodb:*  |
| Resource | ARN path    | 

上表中层次可以描述为

1. Service: dynamodb
2. Action: *
3. Resource: ARN path

*** Group

用于为多个用户配置相同的 policy

*** Federated Users

外部用户在 AWS account 没有对应的 identities，因此需要创建一个 role，并为 role 分配以 policy。外部来的用户会匹配到一个 role


** resource-based policy

policy 被内联设置在 resource 上，用于跨 AWS account 访问资源 

Question: 跨 AWS account 能否通过 role 来访问？


* SDK for Go

** Install SDK

#+BEGIN_SRC sh
  go get -u github.com/aws/aws-sdk-go/...
#+END_SRC


** Configure SDK

必须提供 region 和 credential 信息（IAM 的 access ID 和 secret access key），可选地设置 retry, log level 配置

*** create session

Create session with =aws/session.NewSession=: provide with region, credentials
#+BEGIN_SRC go
  sess, err := session.NewSession(&aws.Config{
          Region: aws.String("us-west-2"),
          Credentials: credentials.NewStaticCredentials("AKID", "SECRET_KEY", "TOKEN"),
  })
#+END_SRC


*** create client

For example, create an S3 client instance from a session (=github.com/aws/aws-sdk-go/service/s3=)

#+BEGIN_SRC go
  sess, err := session.NewSession()
  if err != nil {
  }
  svc := s3.New(sess)
#+END_SRC


** Misc

*** pagination

如果一次请求返回数据过多，可能会分页

1. 判断 isTruncated 是否为真
2. 重新请求，并将上次返回的 marker 作为重新请求的参数传入

* MISC

** Can CIDR be changed for VPC?

No. 

1. Can associate a seconadary IPv4 CIDR block with your VPC.
2. snapshot all resources, delete VPC, create new VPC, restore resources

https://aws.amazon.com/premiumsupport/knowledge-center/vpc-ip-address-range/
