<!DOCTYPE html>
<html>
	<head>
		<title>csapp-digest.org</title>
		<link rel="stylesheet" href="/diary/resources/css/main.css" />
		<link rel="stylesheet" href="/diary/resources/highlight/styles/default.css" />
		<script src="/diary/resources/js/jquery-3.4.1.min.js"></script>
		<script src="/diary/resources/js/swgen.js"></script>
		<script src="/diary/resources/highlight/highlight.pack.js"></script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
		<script>hljs.initHighlightingOnLoad();</script>
	</head>
	<body>
		<nav id='content'>
		</nav>
		<section class="main-article-area">
			<div id='main'>
				<h1 id="a-tour-of-computer-system">A Tour of Computer System</h1>
<p>Computer system consists of</p>
<ol class="incremental">
<li>hardward</li>
<li>system software</li>
<li>application programs</li>
</ol>
<p>The underlying concepts are the same event for different implements.</p>
<p>常见的问题如数字格式、C 程序优化、链接、内存泄露、并行程序开发等。都将在后续展开。</p>
<h2 id="infomation-is-bits-context">Infomation is Bits + Context</h2>
<p>计算机中所有的信息都以一系列的位来表示。例如，源代码文件，以字节（8位）为单位保存在文件中。其编码由 ASCII 定义。</p>
<p>不同的位表示不同的意思的本质在于上下文（Context）。</p>
<div class="aside">
<p>C 语言于 1969-1973 年在贝尔实验室被创造。由 ANSI C 和 ISO 标准化，著名书籍是 K&amp;R。</p>
<p>C program language has below features</p>
<ol class="incremental">
<li>portable and associated with UNIX tightly</li>
<li>small and simple</li>
<li>paratical purpose</li>
</ol>
</div>
<h2 id="programs-are-translated-by-other-programs-into-different-form">Programs Are Translated by Other Programs into different form</h2>
<p>程序以人类可读的程序语言写成（如 C 语言或汇编语言），需要将之翻译为机器可以识别的机器语言（二进制的可执行文件）。</p>
<p>通常的 C 源码需要经过 4 个步骤生成最终可执行文件，如下</p>
<table>
<thead>
<tr class="header">
<th>STEPS</th>
<th>DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>preprocessor(cpp)</td>
<td>用于展开头文件(.i)</td>
</tr>
<tr class="even">
<td>compiler(cc1)</td>
<td>翻译成汇编文件(.s)</td>
</tr>
<tr class="odd">
<td>assembler(as)</td>
<td>汇编生成 relocatable 文件(.o)</td>
</tr>
<tr class="even">
<td>linker(ld)</td>
<td>生成可执行文件</td>
</tr>
</tbody>
</table>
<div class="aside">
<p>GNU 项目由 Richard Stallman 于 1984 年发起，提供了诸多工具，如 emacs, gcc, gdb, as, linker 等 。linux 亦是基于 GNU 提供的工具构建的。</p>
</div>
<h2 id="it-pays-to-understand-how-compilation-system-work">It Pays to Understand How Compilation System Work</h2>
<p>编译器作了太多的事情，为此我们需要了解其细节，以便在以下方面进行优化：</p>
<ol class="incremental">
<li>优化性能：只有知道了编译器原理才能写出更好的高级语言。常见的问题如
<ul class="incremental">
<li>switch 与 if-else 的性能对比</li>
<li>函数调用开销有多大</li>
<li>while 和 for 的开销</li>
<li>pointer 和 array 的开销</li>
<li>解引用与直接访问本地变量的开销</li>
<li>算术顺序对性能的影响</li>
<li>I32 与 x86-64 的指令系统</li>
<li>内存管理</li>
</ul></li>
<li>Understand link-time error，例如
<ul class="incremental">
<li>找不到引用</li>
<li>static 与 global 变量</li>
<li>global 变量重名</li>
<li>静态库与动态库</li>
<li>库的顺序对正确的影响</li>
<li>运行时发生的错误</li>
</ul></li>
<li>Avoiding security holes：
<ul class="incremental">
<li>限制从未知数据源获取数据</li>
<li>注意栈上的存储方式可能造成信息泄漏</li>
</ul></li>
</ol>
<h2 id="processors-read-and-interrupt-instructions-stored-in-memory">Processors Read and Interrupt Instructions Stored in Memory</h2>
<p>正常执行程序时，通过 shell 调用可执行程序。实际在底层复杂无比，归纳起来过程如下：</p>
<ol class="incremental">
<li>shell 交互输入参数到内存</li>
<li>加载可执行文件内容到内存（DMA 技术）</li>
<li>执行</li>
<li>退出</li>
</ol>
<p>其中涉及到计算机的硬件组成。如下图所示：</p>
<figure>
<img src="./img/hardware-org.png" alt="" /><figcaption>Hardware organization</figcaption>
</figure>
<p>硬件中包含几个核心部件，如 CPU，内存，IO 设备，总线等。</p>
<dl class="incremental">
<dt>总线</dt>
<dd>用于沟通各个组件，以 word 为单位（4字节或8字节）进行传送
</dd>
<dt>IO 设备</dt>
<dd>包括输入、输出、存储和网络，通过 controller/adapter<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> 接到 IO 总线上
</dd>
<dt>主存</dt>
<dd>DRAM (Dynamic Random Access Memory)，通过唯一的连续地址来访问
</dd>
<dt>处理器</dt>
<dd>CPU 核心（如 PC，寄存器，ALU单元），根据指令集<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>进行取指、择指、执行、下一条的循环过程，常见操作如 load,store,operate,jump 等
</dd>
</dl>
<h2 id="caches-matters">Caches Matters</h2>
<p>机器指令中的很大一部分工作都是在外部存储、内存、寄存器和外设之间移动数据。</p>
<p>而存储的容量与读写的效率成反比，而且差距还在增大。所以需要考虑如何优化 拷贝的效率。一个关键的问题称为 processor-memory gap：处理器性能与内存 读取的鸿沟。通过添加 cache memory 来缓存近线数据来弥补数据的速度与容量 的差距性。</p>
<h2 id="storage-devices-from-a-hierarchy">Storage Devices From a Hierarchy</h2>
<figure>
<img src="img/memory-hierarchy.png" alt="" /><figcaption>Memory Hierarchy</figcaption>
</figure>
<p>主流解决方案采用三级缓存，CPU 缓存使用 SRAM(static random access memory) 技术。</p>
<p>其中寄存器视为第 0 级缓存，自上向下速度越来越慢，而存储空间越来越大。</p>
<h2 id="the-operating-system-manages-the-hardware">The Operating System Manages the Hardware</h2>
<p>操作系统作为中间层，隔离了应用软件与硬件，其作用有两个：</p>
<ol class="incremental">
<li>保护硬件的正常运行</li>
<li>提供对硬件复杂性的封装，提供一致的、高效的接口</li>
</ol>
<p>操作系统对硬件作出抽象，其中主要包括</p>
<ul class="incremental">
<li>files</li>
<li>virtual memory</li>
<li>processor</li>
</ul>
<div class="aside">
<dl class="incremental">
<dt>Unix</dt>
<dd><p>诞生于 Multics 项目之后，由贝尔实验室 Ken Tompson 和 Dennis Ritchie 等在 DEC PDP-7 机器上实现，于 1973 年用 C 重写，并于 1974 年对外发布。</p>
<dl class="incremental">
<dt>BSD</dt>
<dd>伯克利版本 UNIX，加入了 Internet 支持和虚拟内存支持
</dd>
<dt>System V.</dt>
<dd>贝尔实验室后续版本
</dd>
<dt>Solaris</dt>
<dd>Sun 公司基于二者开发的版本
</dd>
</dl>
</dd>
<dt>Posix</dt>
<dd><p>IEEE 牵头制定的 UNIX 标准，包括系统调用的 C 接口，shell, utilities，thread 及 network programming。由 Richard Stallman 命名</p>
</dd>
</dl>
</div>
<h3 id="processes">Processes</h3>
<p>进程是对正在运行的程序的一个抽象描述。每个进程都有自己独立的计算、内存及 IO 资源。</p>
<p>操作系统通过上下文切换来时分复用，达到多个进程同时运行（concurrently）的效果。多核环境下，可以有真正的并行（parallelism）</p>
<p>上下文切换需要保存 PC 指针、Register file、Content of main memory 信息，涉及到操作系统与硬件的配合</p>
<h3 id="threads">Threads</h3>
<p>在一个进程中的上下文中可以有多个线程，线程共享代码和全局数据，因此更容易共享数据，效率较高</p>
<h3 id="virtual-memory">Virtual Memory</h3>
<p>在每个进程看来，自己独占了整个内存，称为 virtual address space。实际上 由操作系统在上下文切换时，通过硬件的转换机制伪造出相应的内存视图。可以 看作用硬盘来保存进程的虚拟内存，而使用 main memory 作为缓存提高效率。</p>
<p>进程的内存分为多个区域，存储代码和数据，以及某些公共区域，如下图所示</p>
<figure>
<img src="img/virutal-memory.png" alt="" /><figcaption>Virtual Memory</figcaption>
</figure>
<p>其中自下往上依次为：</p>
<ul class="incremental">
<li>code 在放在低地址的固定区域</li>
<li>C 中的全局变量存储</li>
<li>堆区域，在运行时通过 malloc 和 free 来动态扩展</li>
<li>shared libraries，用于动态链接</li>
<li>stack，保存函数调用时参数和返回传递，向下增长</li>
<li>kernel virtual memory 位于高地址，程序不可用</li>
</ul>
<h3 id="files">Files</h3>
<p>文件是对 I/O 设备的一种抽象。其本质是一堆字节，并提供了读写操作。文件 的作用是统一了 I/O 设备的视图，并提供不同设备、不同平台间的移植性。</p>
<p>Unix 中一切皆文件，因此也称作 Unix I/O</p>
<div class="aside">
<dl class="incremental">
<dt>Linux Project</dt>
<dd>Linus Torvalds 于 1991 年作为业余项目实现的一个类 UNIX 操作系统，受 Minix 启发，并兼容 Posix 标准。与 GNU 项目关系密切
</dd>
</dl>
</div>
<h2 id="system-communicate-with-other-system-using-network">System Communicate with Other System Using Network</h2>
<p>计算机系统并不只是以单机运行的。越来越多的价值从互联之中发掘。计算机通过网络与其它计算机交换数据，网络也是一种 I/O 设备</p>
<h2 id="important-themes">Important Themes</h2>
<h3 id="concurrency-and-parallelism">Concurrency and Parallelism</h3>
<p>There are two simliar concepts about multiple execution implement ways</p>
<dl class="incremental">
<dt>Concurrency</dt>
<dd>To do more at the same time
</dd>
<dt>Parallelism</dt>
<dd>To do more and also fast at the same time
</dd>
</dl>
<p>There're 3 levels of parallelism abstract</p>
<ol class="incremental">
<li>Thread Level</li>
<li>Instruction Level</li>
<li>SIMD Level</li>
</ol>
<h4 id="thread-parallelism">Thread Parallelism</h4>
<p>Each Process can have multiple control flows. Operation System switch between threads (by backup and restore its context) rapidly in time shared manner to simulate parallel executions.</p>
<p>The origin aims of multiple threads is for the benefits of :</p>
<ul class="incremental">
<li>Multiple users</li>
<li>Single user with multiple tasks</li>
</ul>
<p>In the early days, the <strong>uniprocessor system</strong>'s multiple threads are just simulation for parallelism. The later <strong>multiprocessor system</strong> can run threads in real parallel manners.</p>
<p>There are 2 technologies in multiple processors system:</p>
<dl class="incremental">
<dt>multiple cores</dt>
<dd>each core has its own L1/L2 cache and resides in the same chip
</dd>
<dt>hyperthreading</dt>
<dd>each CPU has multiple copies of register and hardwares, can execute multiple tasks at same time
</dd>
</dl>
<p>Parallelism can be benefit for improve performances in aspects:</p>
<ol class="incremental">
<li>real multiple tasks</li>
<li>need new methods to program that can dig out the advantages of multiprocessor</li>
</ol>
<h4 id="instruction-parallelism">Instruction Parallelism</h4>
<p>The most famous method is <strong>pipeline</strong> which execute instruction's setps in parrel and improve the performance faster than execute instruction for the whole cycles.</p>
<p>The technology to execution rates if faster than one instruction per cycle is called <strong>superscalar</strong></p>
<h4 id="simd-parallelism">SIMD Parallelism</h4>
<ul class="incremental">
<li>SIMD is short for Single Instruction Multiple Data.</li>
<li>Mostly used to speed up image, sound, video procses.</li>
<li>Need language (data type) and compiler supports.</li>
</ul>
<h3 id="the-importance-of-abstraction-of-computer-system">The Importance of Abstraction of Computer System</h3>
<p><strong>Abstraction</strong> is one of the most important concept in Computer Science.</p>
<p>The import abstractions are:</p>
<dl class="incremental">
<dt>API</dt>
<dd>prototype which user doesn't need to delve into details
</dd>
<dt>Program Language</dt>
<dd>Abstraction concept like class, function
</dd>
<dt>ISA (Instruction Set Architecture)</dt>
<dd>Abstraction of sequential execution model for hardware implements (Different hardware can have different implement but share the machine code)
</dd>
<dt>File</dt>
<dd>Abstraction of I/O
</dd>
<dt>Virtual Memory</dt>
<dd>Abstraction Linear memory for program
</dd>
<dt>Process</dt>
<dd>Abstraction of a running program
</dd>
<dt>Virtual Machine</dt>
<dd>Abstraction of computer hardware
</dd>
</dl>
<h1 id="representing-and-manipulating-informations">Representing and Manipulating Informations</h1>
<h2 id="overview">Overview</h2>
<p>Computer information is represented in binary mode. The reason to express information with 2-vlaue bits is because its readily be represented, stored and transmitted.</p>
<p>We group bits and apply rules to interprete them for given meaning of bit pattern. That is called Data Type.</p>
<p>The reasons why we programmers should dive deep into the representation of data are listed below:</p>
<ol class="incremental">
<li>write correct and portable program for different platforms</li>
<li>improve performance</li>
<li>security cause</li>
<li>understand machine-level program</li>
</ol>
<p>Different types of number has three representations</p>
<ol class="incremental">
<li>unsigned integer</li>
<li>signed integer</li>
<li>floating-point</li>
</ol>
<p>For integer representations, it can be encoded for a comparatively small range of values, but do so precisely. While floating-point representations can encode a wide range of values, but only approximately.</p>
<p>Here's an example to show why we should be careful for the representation of data (floating-point arithmetic doesn't conform the association rule):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1"></a>(<span class="fl">3.14</span> + <span class="fl">1e20</span>) - <span class="fl">1e20</span>            <span class="co">/* 0.0 */</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fl">3.14</span> + (<span class="fl">1e20</span> - <span class="fl">1e20</span>)            <span class="co">/* 3.14 */</span></span></code></pre></div>
<h3 id="c-standard">C standard <span class="tag" data-tag-name="c"><span class="smallcaps">c</span></span></h3>
<p>For GNU c compiler</p>
<ol class="incremental">
<li><code>--ansi</code> or <code>--std=c89</code>: ANSI C(1989)/ISO C99(1990)</li>
<li><code>--std=gnu89</code>: GNU extends for ANSI C</li>
<li><code>--std=c99</code>: ISO C99(1999)</li>
<li><code>--std=gnu99</code>: GNU extends for ISO C99</li>
</ol>
<h2 id="information-storage">Information Storage</h2>
<p>We use <strong>bytes</strong> as the unit of memory which is consisted by 8 bits.</p>
<p>The virtual memory that program visits can be regarded as an array of bytes. Each bytes is indexed by <strong>address</strong>. Underlying the virtual memroy, it's made up of RAM, disk storage, special hardware, OS and provides the program with what appears to be a monolithic bytes array.</p>
<p><code>Pointer = Address + DataType</code></p>
<p>Actually, C compiler maintains pointer's type information, the machine-level program it generates has no information about data types.</p>
<p>Pointer are the central feature of C:</p>
<ol class="incremental">
<li>can be used to refer elements of data structure</li>
<li>combine value and type (provide flexible in program language)</li>
</ol>
<h3 id="hexadecimal-notation">Hexadecimal Notation</h3>
<p>Because of the representation in binary notation is too tedious. It's convinent to use hexadecimal notation to represent integer (such as <code>0xFA1D37BB</code>)</p>
<p>It's necessary to know how to convert among binary, decimal and hexadecimal:</p>
<dl class="incremental">
<dt>hex to bin</dt>
<dd>expand each hexadecimal to 4 bits binary
</dd>
<dt>bin to hex</dt>
<dd>split into groups of 4 bits (make the leftmost group be the one with fewer than 4bits and padding with leading zeros)
</dd>
<dt>hex to dec</dt>
<dd>multiplication methods
</dd>
<dt>dec to hex</dt>
<dd>division methods
</dd>
</dl>
<p>Some useful conversion or notation list below:</p>
<table>
<tbody>
<tr class="odd">
<td>2<sup>7</sup></td>
<td>128</td>
</tr>
<tr class="even">
<td>2<sup>8</sup></td>
<td>256</td>
</tr>
<tr class="odd">
<td>2<sup>10</sup></td>
<td>1024</td>
</tr>
<tr class="even">
<td>2<sup>16</sup></td>
<td>65536</td>
</tr>
</tbody>
</table>
<p>And <span class="math inline">\(2^n\)</span> in binary notation is a string starts with 1 followed by n zero.</p>
<h3 id="words">Words</h3>
<p>Bytes group to word. It's the nominal size of integer and pointer data.</p>
<p>The word is used to express virtual address. For 32bit platform, the memory address is in range from 0 to <span class="math inline">\(2^32-1\)</span> (4G bytes).</p>
<p>The 64bit platform extends the max available memory address to <span class="math inline">\(2^64-1\)</span>.</p>
<h3 id="data-sizes">Data Sizes</h3>
<p>The typeical data sizes (in C language) shows in the table below:</p>
<table>
<thead>
<tr class="header">
<th>data type</th>
<th>32 bit</th>
<th>64 bit</th>
<th>note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>char</td>
<td>1</td>
<td>1</td>
<td></td>
</tr>
<tr class="even">
<td>short int</td>
<td>2</td>
<td>2</td>
<td></td>
</tr>
<tr class="odd">
<td>int</td>
<td>4</td>
<td>4</td>
<td></td>
</tr>
<tr class="even">
<td>long int</td>
<td>4</td>
<td>8</td>
<td>the main different between 32bit and 64bit platforms</td>
</tr>
<tr class="odd">
<td>long long</td>
<td>8</td>
<td>8</td>
<td>defined in ISO C99 standard. supported by compiler in 32bit platform</td>
</tr>
<tr class="even">
<td>char*</td>
<td>4</td>
<td>8</td>
<td>word size of platform</td>
</tr>
<tr class="odd">
<td>float</td>
<td>4</td>
<td>4</td>
<td></td>
</tr>
<tr class="even">
<td>double</td>
<td>8</td>
<td>8</td>
<td></td>
</tr>
</tbody>
</table>
<p>The real data sizes depends on both the machine and the compiler.</p>
<p>It's very important to write portable code which is insentitive to the exact sizes of different data types.</p>
<p>For example, in history, <code>int</code> can be used to store a pointer in 32bit platform. But it's a fault error in 64bit platform.</p>
<h2 id="integer-representations">Integer Representations</h2>
<h2 id="integer-arithmetic">Integer Arithmetic</h2>
<h2 id="floating-point">Floating Point</h2>
<h1 id="处理器体系结构"><span class="todo TODO">TODO</span> 处理器体系结构</h1>
<ul class="incremental">
<li>ISA，指处理器指令和指令处理的数据集</li>
<li>作为在编译器与处理器之间中间层
<ul class="incremental">
<li>编译器只需要知道哪些指令可用</li>
<li>处理器建造出执行这些指令的处理器</li>
</ul></li>
</ul>
<h1 id="virtual-memory-1">[7/13] Virtual Memory</h1>
<h2 id="overview-1"><span class="done DONE">DONE</span> Overview</h2>
<p>与 CPU 共享不同，CPU 共享最多因为进程数增大而变慢。内存共享可能会有其它问题</p>
<ol class="incremental">
<li>某些进程得不到需要的内存</li>
<li>内存内容被破坏</li>
</ol>
<p>Modern systems provide an abstraction of main memory known as <em>virtual memory</em> (VM).</p>
<p>Virtual memory is an elegant interaction to provide each process with a address space that is</p>
<ul class="incremental">
<li>large</li>
<li>uniform</li>
<li>private</li>
</ul>
<p>The aspects to interact with are</p>
<ul class="incremental">
<li>hardware exception</li>
<li>hardware address translation</li>
<li>main memory</li>
<li>disk file (swap)</li>
<li>kernel software</li>
</ul>
<p>Virtual memory provides 3 important capabilities:</p>
<dl class="incremental">
<dt>swap</dt>
<dd>use main memory effciently by treating it as a cache for an address space stored on disk, keeping only the active areas in main memory and transferring data back and forth between disk and memory as needed
</dd>
<dt>flat address</dt>
<dd>it simplifies memory management by providing each process with a uniform address space
</dd>
<dt>isolation</dt>
<dd>it protects the address space of each process from corruption by other processes
</dd>
</dl>
<h3 id="why-would-a-programmer-need-to-understand-it">Why would a programmer need to understand it?</h3>
<dl class="incremental">
<dt>central</dt>
<dd>pervades all levels of computer systems: hardware exception, assemblers, linkers, loaders, shared objects, files and processes
</dd>
<dt>powerful</dt>
<dd><code>malloc</code>, <code>mmap</code>, share memory with other processes
</dd>
<dt>dangerous</dt>
<dd>segmentation fault or protection fault
</dd>
</dl>
<h3 id="two-angles-to-learn-virtual-memory">Two angles to learn virtual memory</h3>
<ol class="incremental">
<li>how does it work</li>
<li>how it is used and managed by application</li>
</ol>
<h2 id="physical-and-virtual-addressing"><span class="done DONE">DONE</span> Physical and Virtual Addressing</h2>
<dl class="incremental">
<dt>PA (physical address)</dt>
<dd>is organized as an array of M contiguous byte-size cells.
</dd>
<dt>VA (virtual address)</dt>
<dd>is converted to the appropriate physical address before being sent to main memory.
</dd>
<dt>MMU (Memory management unit)</dt>
<dd>using a lookup table stored in main memory, whose contents are managed by the operating system, to perform the address transferring
</dd>
</dl>
<h2 id="address-spaces"><span class="done DONE">DONE</span> Address Spaces</h2>
<p><em>linear address space</em> is the consecutive address space that is represented with the number of bits (32-bit or 64-bit).</p>
<p>Each data object, represented with several bytes, has the address attribute. Each object can have multiple independent addresses, each chosen from a different address space. (?)</p>
<table>
<thead>
<tr class="header">
<th>VA bits</th>
<th>Number of VA</th>
<th>Largest possible virtual address</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>4</td>
<td>16</td>
<td>15</td>
</tr>
<tr class="even">
<td>14</td>
<td>16K</td>
<td>16K-1</td>
</tr>
<tr class="odd">
<td>24</td>
<td>16M</td>
<td>16M-1</td>
</tr>
<tr class="even">
<td>46</td>
<td>64T</td>
<td>64T-1</td>
</tr>
<tr class="odd">
<td>54</td>
<td>16P</td>
<td>16P-1</td>
</tr>
</tbody>
</table>
<h2 id="vm-as-a-tool-for-caching"><span class="done DONE">DONE</span> VM as a Tool for Caching</h2>
<p>Cache the contiguous addressed disk space into virtual memory in unit of fix sized block:</p>
<dl class="incremental">
<dt><em>virtual pages</em> (VPs)</dt>
<dd>for virtual memory
</dd>
<dt><em>physical pages</em> (PPs)</dt>
<dd>for physical memory, also referered as <em>page frames</em>
</dd>
</dl>
<p>Virtual pages is partitioned into 3 disjoint subsets:</p>
<dl class="incremental">
<dt>Unallocated</dt>
<dd>pages have not yet been allocated by VM system (has no data associated with)
</dd>
<dt>Cached</dt>
<dd>cached in physical memory
</dd>
<dt>UnCached</dt>
<dd>allocated pages that are not cached in physical memory (only in disk)
</dd>
</dl>
<p>By the cache meachanism, system can provide larger virtual address space that the available physical address.</p>
<figure>
<img src="./img/9.3.vp-pp-mapping.jpg" alt="" /><figcaption>VM as Cache</figcaption>
</figure>
<h3 id="dram-cache-organization">DRAM Cache Organization</h3>
<h4 id="term">Term</h4>
<ul class="incremental">
<li><strong>SRAM</strong> cache denotes the L1, L2, and L3 cache memories between the CPU and main memory.</li>
<li><strong>DRAM</strong> cache to denote the VM system's cache that caches virtual pages in main memory.</li>
</ul>
<h4 id="compare">Compare</h4>
<p>DRAM is important because of</p>
<ol class="incremental">
<li>read from disk is too slow (about 100,000 slower than a DRAM)</li>
<li>read the first byte from a disk sector is about 100,000 times slower than reading successive bytes in the sector</li>
</ol>
<p>The bottom line is that the organization of the DRAM cache is driven entirely by the enormous cost of misses.</p>
<h3 id="page-tables">Page Tables</h3>
<p>Determine</p>
<ul class="incremental">
<li>which <strong>physical page</strong> it is cached in if a <strong>virtual page</strong> is cached</li>
<li>Or the data is stored on disk
<ul class="incremental">
<li>determine where it is stored</li>
<li>select a victim page in physical memory</li>
<li>copy the virtual page from disk to DRAM, replacing the victim page</li>
</ul></li>
</ul>
<p>These capabilites are provided by</p>
<ol class="incremental">
<li><strong>MMU</strong> (hardware) for address translating: read the mapping rules from <strong>page table</strong></li>
<li><strong>page table</strong>: OS maintain a data structure in physical memory that maps virtual pages to physical pages</li>
</ol>
<figure>
<img src="./img/page-table.png" alt="" /><figcaption>Page Table</figcaption>
</figure>
<p>In the figure above:</p>
<ul class="incremental">
<li>PTE (<em>page table entries</em>): is the element type of page table, contains <code>valid</code> and <code>address</code> fields</li>
<li>each page in VA space has a PTE at a <strong>fixed offset</strong> in the page table</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Valid</th>
<th>Address</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>addr</td>
<td>virtual page is currently cached in physical address `addr` in DRAM</td>
</tr>
<tr class="even">
<td>0</td>
<td>null</td>
<td>unallocated</td>
</tr>
<tr class="odd">
<td>0</td>
<td>addr</td>
<td>address points to the start of the virtual page on disk</td>
</tr>
</tbody>
</table>
<h4 id="practice-problem-9.2">Practice Problem 9.2</h4>
<p>determine the number of PTEs that are needed for the following combinations of virtual address size (n) and page size (P):</p>
<pre><code>nPTEs = (1&lt;&lt;n) / P
</code></pre>
<table>
<thead>
<tr class="header">
<th>n</th>
<th><span class="math inline">\(P = 2^p\)</span></th>
<th>Number of PTEs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>12</td>
<td>1K</td>
<td>4</td>
</tr>
<tr class="even">
<td>16</td>
<td>16K</td>
<td>4</td>
</tr>
<tr class="odd">
<td>24</td>
<td>2M</td>
<td>8</td>
</tr>
<tr class="even">
<td>36</td>
<td>1G</td>
<td>64</td>
</tr>
</tbody>
</table>
<h3 id="page-hits">Page Hits</h3>
<p>When visiting the cached virtual page, the MMU will translate the address to the real address in physical memory.</p>
<h3 id="page-faults">Page Faults</h3>
<p><em>page fault</em>: a virtual page cache miss happened when MMU is trying to get the physical memory.</p>
<p>A <em>page fault exception</em> will invoke the handler in kernel to select a victim page and</p>
<ul class="incremental">
<li>copy to disk if another virtual page (VPx) mapped to this PP (PPx) and has been modified</li>
<li>disassociate the PTE for VPx (uncached)</li>
<li>copy the disk cache to PPx in memory</li>
<li>update PTE this VP</li>
<li>return from handler</li>
<li>restarts the faulting instruction</li>
</ul>
<p>The virtual memory block is also known as <em>pages</em>. The activity of transferring a page between disk and memory is known as <em>swapping</em> or <em>paging</em>. Pages are <em>swapped in (paged in)</em> from disk to DRAM, and <em>swapped out (paged out)</em> from DRAM to disk. The strategy of waiting until the last moment to swap in a page, when a miss occurs, is known as <em>demand paging</em>.</p>
<h3 id="allocating-page">Allocating Page</h3>
<p>After previous PP being swapped out, its VPE now points to a block located on disk.</p>
<h3 id="locality-to-the-rescue-again">Locality to the Rescue Again</h3>
<p>Virtual memory's performance is benefited by the <em>locality</em>. The principle of locality promises that at any point in time they will tend to work on a smaller set of <em>active pages</em> known as the <em>working set</em> or <em>resident set</em>.</p>
<p>Terms <em>thrashing</em> means pages are swapped in and out continuously.</p>
<p>In Linux, we can use <code>getrusage</code> (get resource usgae) API to check the page faults ratio of a process (or process group). See <code>rusage.ru_majflt</code> field in <code>man 2 getrusage</code>.</p>
<h2 id="vm-as-a-tool-for-memory-management"><span class="done DONE">DONE</span> VM as a Tool for Memory Management</h2>
<p>By using seperated page tables, OS can provide sepearte virtual address space for each process. Notice that multiple virtual pages can be mapped to the same shared physical page.</p>
<figure>
<img src="./img/multiple-page-table.png" alt="" /><figcaption>VM for memory management</figcaption>
</figure>
<p>The combination of demand paging and separate virtual address spaces has a profound impact on the way that memory is used and managed in a system:</p>
<dl class="incremental">
<dt>simplifying linking</dt>
<dd>each process can use the same basic format (layout of segments) for its memory image
</dd>
<dt>simplifying loading</dt>
<dd>allocate virtual pages for code and data segments, and marks them as uncached, and points their PET to the location object files (load segment as needed). See also <code>mmap</code>
</dd>
<dt>simplifying sharing</dt>
<dd>map private virtual pages to disjoint physical pages. And share common library, such as <code>printf</code>, between different processes (share the same physical pages)
</dd>
<dt>simplifying memory allocation</dt>
<dd>the virtual memory allocated by <code>malloc</code> can scatter randomly in physical memory
</dd>
</dl>
<h2 id="vm-as-a-tool-for-memory-protection"><span class="done DONE">DONE</span> VM as a Tool for Memory Protection</h2>
<p>MMU provides access control by read the PTE's permission bits. Any violation will trigger a general <strong>protection fault</strong> and get a <code>SIGSEGV</code> signal in the offending process (the notorious <strong>segmentation fault</strong> error)</p>
<table>
<thead>
<tr class="header">
<th>Bit Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SUP</td>
<td>Supervisor: must be running in kernel mode to access the page</td>
</tr>
<tr class="even">
<td>READ</td>
<td>read permission to the page</td>
</tr>
<tr class="odd">
<td>WRITE</td>
<td>write permission to the page</td>
</tr>
</tbody>
</table>
<h2 id="address-translation"><span class="done DONE">DONE</span> Address Translation</h2>
<h3 id="overview-2">Overview</h3>
<p>The page size (P bytes) is same in virtual space and physical space. Virtual space may be smaller, or equal, or larger than physical address space.</p>
<p>Address translation is a mapping between the element of an N-element virtual address space (VAS) and an M-element physical address space (PAS) <span class="math display">\[ MAP: {VAS} \rightarrow  {PAS} \cup \emptyset \]</span></p>
<p>A <em>page fault</em> exception will be triggered if the data at virtual addr is not present in physical memory.</p>
<h4 id="terms-of-virtual-address">Terms of virtual address</h4>
<table>
<thead>
<tr class="header">
<th>symbol</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VPO</td>
<td>virtual page offset (bytes)</td>
</tr>
<tr class="even">
<td>VPN</td>
<td>virtual page number</td>
</tr>
<tr class="odd">
<td>TLBI</td>
<td>TLB index</td>
</tr>
<tr class="even">
<td>TLBT</td>
<td>TLB tag</td>
</tr>
<tr class="odd">
<td>TLB</td>
<td>table base register</td>
</tr>
</tbody>
</table>
<h4 id="terms-of-physical-address">Terms of physical address</h4>
<table>
<thead>
<tr class="header">
<th>symbol</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PPO</td>
<td>physical page offset (bytes)</td>
</tr>
<tr class="even">
<td>PPN</td>
<td>physical page number</td>
</tr>
<tr class="odd">
<td>CO</td>
<td>byte offset within cache block</td>
</tr>
<tr class="even">
<td>CI</td>
<td>cache index</td>
</tr>
<tr class="odd">
<td>CT</td>
<td>cache tag</td>
</tr>
</tbody>
</table>
<h4 id="address-translation-1">Address Translation</h4>
<p><em>page table base register</em> (PTBR) in CPU points to current page table.</p>
<p>An virtual address is constructed with two parts:</p>
<ol class="incremental">
<li><em>p</em>-bit <em>virtual page offset</em> (VPO)</li>
<li><em>(n-p)</em>-bit <em>virtual page number</em> (VPN)</li>
</ol>
<p>MMU use the VPN to select the appropriate PTE (pointed by PTBR) and get the <em>physical page number</em> (PPN). Then calculate the real physical address by add the offset (VPO/PPO) to the physical base address.</p>
<figure>
<img src="./img/address-translation.png" alt="" /><figcaption>Address translation with a page table</figcaption>
</figure>
<h4 id="page-hit">page hit</h4>
<p>The page hit steps are</p>
<ol class="incremental">
<li>CPU generate a VA and send it to the MMU</li>
<li>MMU generate the PTE address and requests it from the cache/main memory</li>
<li>The cache/main memory returns the PTE to the MMU</li>
<li>The MMU constructs the physical address and sends it to the cache/main memory</li>
<li>The cache/main memory returns the requested data word to the processor.</li>
</ol>
<figure>
<img src="./img/page-hit.png" alt="" /><figcaption>Page hit</figcaption>
</figure>
<h4 id="page-fault">page fault</h4>
<p>The page fault is handled by operating system kernel</p>
<ol class="incremental">
<li>CPU generate a VA and send it to the MMU</li>
<li>MMU generate the PTE address and requests it from the cache/main memory</li>
<li>MMU triggers an exception if the valid bit in the PTE is zero and transfer control in the CPU to a page fault exception handler</li>
<li>The fault handler identifies a victim page in physical memory, and if that page has been modified, pages it out to disk.</li>
<li>The fault handler pages in the new page and update the PTE in memory.</li>
<li>The fault handler returns to the origin process, causing the faulting instruction to be restarted.</li>
<li>back to the page hit steps.</li>
</ol>
<figure>
<img src="./img/page-fault.png" alt="" /><figcaption>Page fault</figcaption>
</figure>
<h4 id="practice-problem-9.3">Practice Problem 9.3</h4>
<p>Given a 64-bit virtual address space and a 32-bit physical address, determine the number of bits in the VPN, VPO, PPN and PPO for each page size P:</p>
<table>
<thead>
<tr class="header">
<th>P</th>
<th>VPN</th>
<th>VPO</th>
<th>PPN</th>
<th>PPO</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1KB</td>
<td>54</td>
<td>10</td>
<td>22</td>
<td>10</td>
</tr>
<tr class="even">
<td>2KB</td>
<td>53</td>
<td>11</td>
<td>21</td>
<td>11</td>
</tr>
<tr class="odd">
<td>4KB</td>
<td>52</td>
<td>12</td>
<td>20</td>
<td>12</td>
</tr>
<tr class="even">
<td>16KB</td>
<td>50</td>
<td>14</td>
<td>18</td>
<td>14</td>
</tr>
</tbody>
</table>
<h3 id="integrating-caches-and-vm">Integrating Caches and VM</h3>
<p>SRAM caches DRAM which can be access via either virtual or physical addresses.</p>
<p>Most systems opt for physical addressing</p>
<ul class="incremental">
<li>straightforward for multiple processes to have blocks in the cache at the same time</li>
<li>share blocks from the same virtual pages</li>
<li>doesn't have to deal with protection issues</li>
</ul>
<p>The main idea is that the address translation occurs before the cache lookup</p>
<figure>
<img src="./img/vm-with-pa-cache.png" alt="" /><figcaption>Integrating VM with a physically addressed cache</figcaption>
</figure>
<h3 id="speeding-up-address-translation-with-a-tlb">Speeding Up Address Translation with a TLB</h3>
<p>PTE table is also placed in memory. In the worst case, MMU requires an additional fetch from memory, at a cost of tens to hundreds of cycles.</p>
<p>Many systems include a small cache of PTEs in the MMU called a <em>translation lookaside buffer</em> (TLB).</p>
<p>TBL is a small, virtually addressed cache where each line holds a block consisting of a single PTE.</p>
<figure>
<img src="./img/va-tlb.png" alt="" /><figcaption>Components of a VA to access the TLB</figcaption>
</figure>
<p>VPN is consist by <em>TLB index</em> and <em>TLB tag</em></p>
<ul class="incremental">
<li><em>TLB index</em> consists of the <em>t</em> least significant bits of the VPN 'cause TLB has <span class="math inline">\(T=2^t\)</span> sets</li>
<li><em>TLB tag</em> consists of the remaining bits in the VPN.</li>
</ul>
<figure>
<img src="./img/tlb-hit-and-miss.png" alt="" /><figcaption>Address Translation with a TLB</figcaption>
</figure>
<p>The steps of speeding up address access with TLB are</p>
<ol class="incremental">
<li>CPU generate VA</li>
<li>MMU fetch the appropriate PTE from the TLB (or fetches from L1 cache if TLB is missing and caches it to TLB)</li>
<li>MMU translate the VA to PA and send it to the cache/main memory</li>
<li>The cache/main memory returns the requested data word to the CPU</li>
</ol>
<h3 id="multi-level-page-tables">Multi-Level Page Tables</h3>
<p>For 32-bit address space, 4KB page and a 4-byte PTE</p>
<ul class="incremental">
<li>there will be <span class="math inline">\((1 &lt;&lt; 32) / (1 &lt;&lt; 12)= 1M\)</span> pages</li>
<li>we need a 4 MB page table resident in memory at all times</li>
</ul>
<p>The common approach for compacting the page table is to use a <strong>hierarchy of page tables</strong> instead. For example, we can build a two-level page table hierarchy for VA space</p>
<figure>
<img src="./img/two-level-page-table-hierarchy.png" alt="" /><figcaption>Two-level page table hierarchy</figcaption>
</figure>
<p>split the 4 MB PTE into two level</p>
<dl class="incremental">
<dt>level 1 (contains 1K PTE)</dt>
<dd>map to a page which contain 1K PTE
</dd>
<dt>level 2 (contains 1K PTE)</dt>
<dd>map to a page of virtual memory
</dd>
</dl>
<p>If the chunk <em>i</em> of level 2 is all unallocated, then level 1 PTE <em>i</em> is null.</p>
<p>This scheme reduces memory requirements in two ways</p>
<ol class="incremental">
<li>if a PTE in level 1 table is null, then the corresponding level 2 page table does not even have to exist</li>
<li>only level 1 table (4 KB) need to be in main memory at all times.</li>
</ol>
<p>Figure below summarizes address translation with a <em>k-level</em> page table hierarchy:</p>
<figure>
<img src="./img/address-translation-with-k-level-page-table.png" alt="" /><figcaption>Address translation with a k-level page table</figcaption>
</figure>
<ul class="incremental">
<li>Virtual address is partitioned into <em>k</em> VPNs and a VPO</li>
<li>each VPN i is an index into a page table at level <em>i</em></li>
<li>each PTE in a level <em>j</em> table points to the base of some page table at level <span class="math inline">\(j + 1\)</span></li>
<li>each PTE in a level <em>k</em> (at last VPN) table contains either the PPN of some physical page or the address of a disk block</li>
<li>MMU must access <em>k</em> PTEs before it can determine the PPN</li>
<li>PPO is identical to the VPO</li>
</ul>
<p>Accessing <em>k</em> PTEs may seem expensive and impractical at first glance. However, the TLB comes to the rescue here by caching PTEs from the page tables at the different levels. In practice, address translation with multi-level page tables is not significantly slower than with single-level page tables.</p>
<h3 id="putting-it-together-end-to-end-address-translation">Putting It Together: End-to-End Address Translation</h3>
<p>Concrete example of end-to-end address translation with a TLB and L1 d-cache.</p>
<table>
<thead>
<tr class="header">
<th>Item</th>
<th>Specification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>virtual address</td>
<td>n = 14</td>
</tr>
<tr class="even">
<td>physical address</td>
<td>m = 12</td>
</tr>
<tr class="odd">
<td>page size</td>
<td>P = 64</td>
</tr>
<tr class="even">
<td>TLB</td>
<td>4-way set (2-bit TLBI) associative with 16 total entries<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
</tr>
<tr class="odd">
<td>L1 d-cache</td>
<td>4-byte line size and 16 total sets</td>
</tr>
</tbody>
</table>
<p>Design of VPN/PPN/VPO/PPO:</p>
<figure>
<img src="./img/addressing-for-small-memory-system.png" alt="" /><figcaption>Addressing for small memory system</figcaption>
</figure>
<ul class="incremental">
<li>the low-order 6 bits of the VA and PA serve as the VPO and PPO</li>
<li>the high-order 8 bits of the virtual address serve as the VPN</li>
<li>the high-order 6 bits of the physical address serve as the PPN</li>
</ul>
<p>Design of the TLB</p>
<ul class="incremental">
<li>the high-order 6 bits of the VPN serve as TLBT</li>
<li>the low-order 2 bits of the VPN serve as TLBI</li>
<li>TLB can cache 4 x 4 entries at most</li>
</ul>
<p>Desgin of the page table</p>
<ul class="incremental">
<li>256 page table entries</li>
<li>these VPNs are not part of the page table and not stored in memory</li>
</ul>
<p>Desgin of the Cache</p>
<ul class="incremental">
<li>low-order 2 bits serve as offset (CO)</li>
<li>next 4 bits serve as the set index (CI)</li>
<li>remaining 6 bits serve as the tag (CT)</li>
</ul>
<p>If the resulting PTE is invalid, then there is a page fault and the kernel must page in the appropriate page and return the load instruction.</p>
<h4 id="notes">Notes</h4>
<p>14bit 的虚拟地址空间，寻址范围为 16KB；12 bit 物理地址空间，寻址范围为 4KB。页大小为 64B ($2<sup>6</sup>$），所以 VPO 和 PPO 均为 6 字节。VPN 为 8 字节， 对应于 256 个PTE。</p>
<p>当不使用 TLB 和 L1-D 缓存时，MMU 在 PTE 中寻找第 i 个表顶， 找出对应的 PPN 地址。根据 $ (PPN &lt;&lt; 6) | PPO $ 得到最终的物理地址。</p>
<p>TLB 中缓存的 16 个 TLE 条目。其中每种 TLBI 缓存四条，实际每种 TLBI 中有 64 条 TLBT。 MMU 首先查询是否在 TLB 中有对应在 (TLBI, TLBT) 缓存，如果存在，则直接得到 PPN 地址， 否则需要在 PTE 表中进行查询，并将结构写入 TLB 缓存中。</p>
<p>物理地址长度为 12, L1-D 缓存中最多可以保存 16 个 4 字节的物理地址数据。 取物理地址的最低两位为偏移量(CO)，次四位为索引（CI）指向 L1-D 的十六个元素， 高 6 位内容作为比较内容。</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode go"><code class="sourceCode go"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">type</span> TLBEntry <span class="kw">struct</span> {</span>
<span id="cb3-2"><a href="#cb3-2"></a>   Tag   bit6</span>
<span id="cb3-3"><a href="#cb3-3"></a>   Valid <span class="dt">bool</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>   PPN   bit6</span>
<span id="cb3-5"><a href="#cb3-5"></a>}</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="kw">type</span> L1CacheEntry <span class="kw">struct</span> {</span>
<span id="cb3-8"><a href="#cb3-8"></a>   Tag   bit6</span>
<span id="cb3-9"><a href="#cb3-9"></a>   Valid <span class="dt">bool</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>   Bytes [<span class="dv">4</span>]<span class="dt">byte</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>}</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="kw">var</span> L1Cache [<span class="dv">16</span>]L1CacheEntry</span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="kw">var</span> TLB [<span class="dv">4</span>]<span class="kw">map</span>[bit6]TLBEntry</span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="kw">func</span> AddressTranslateWithTLB(va bit14) (pa bit12) {</span>
<span id="cb3-17"><a href="#cb3-17"></a>  VPO := va &amp; <span class="dv">0x3F</span></span>
<span id="cb3-18"><a href="#cb3-18"></a>  VPN := va &gt;&gt; <span class="dv">6</span></span>
<span id="cb3-19"><a href="#cb3-19"></a>  TLBI := VPN &amp; <span class="dv">0x11</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>  TLBT := VPN &gt;&gt; <span class="dv">2</span></span>
<span id="cb3-21"><a href="#cb3-21"></a>  <span class="co">// tlb hit</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>  <span class="kw">if</span> entry, ok := TLB[TLBI][TLBT]; ok {</span>
<span id="cb3-23"><a href="#cb3-23"></a>    <span class="kw">return</span> (entry.PPN &lt;&lt; <span class="dv">6</span>) | VPO</span>
<span id="cb3-24"><a href="#cb3-24"></a>  } <span class="kw">else</span> {</span>
<span id="cb3-25"><a href="#cb3-25"></a>    pa := AddressTranslate(va)</span>
<span id="cb3-26"><a href="#cb3-26"></a>    CacheInTLB(pa, va)</span>
<span id="cb3-27"><a href="#cb3-27"></a>    <span class="kw">return</span> pa</span>
<span id="cb3-28"><a href="#cb3-28"></a>  }</span>
<span id="cb3-29"><a href="#cb3-29"></a>}</span>
<span id="cb3-30"><a href="#cb3-30"></a></span>
<span id="cb3-31"><a href="#cb3-31"></a><span class="kw">func</span> ReadPAByteWithCache(pa bit12) <span class="dt">byte</span>{</span>
<span id="cb3-32"><a href="#cb3-32"></a>  CO := (pa &amp; <span class="dv">0x11</span>)</span>
<span id="cb3-33"><a href="#cb3-33"></a>  CI := ((pa &gt;&gt; <span class="dv">2</span>) &amp; <span class="dv">0x0F</span>)</span>
<span id="cb3-34"><a href="#cb3-34"></a>  CT := (pa &gt;&gt; <span class="dv">6</span>)</span>
<span id="cb3-35"><a href="#cb3-35"></a>  entry := L1Cache[CI]</span>
<span id="cb3-36"><a href="#cb3-36"></a>  <span class="co">// cache hit</span></span>
<span id="cb3-37"><a href="#cb3-37"></a>  <span class="kw">if</span> entry.Valid &amp;&amp; entry.Tag == CT {</span>
<span id="cb3-38"><a href="#cb3-38"></a>    <span class="kw">return</span> entry.Bytes[CO]</span>
<span id="cb3-39"><a href="#cb3-39"></a>  } <span class="kw">else</span> {</span>
<span id="cb3-40"><a href="#cb3-40"></a>    <span class="dt">byte</span> := ReadPAByte(pa)</span>
<span id="cb3-41"><a href="#cb3-41"></a>    CacheInL1D(<span class="dt">byte</span>, pa)</span>
<span id="cb3-42"><a href="#cb3-42"></a>    <span class="kw">return</span> <span class="dt">byte</span></span>
<span id="cb3-43"><a href="#cb3-43"></a>  }</span>
<span id="cb3-44"><a href="#cb3-44"></a>}</span></code></pre></div>
<h4 id="practice-problem-9.4">Practice Problem 9.4</h4>
<p>Address translation</p>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VPN</td>
<td>0x0F</td>
</tr>
<tr class="even">
<td>VPO/PPO</td>
<td>0x27</td>
</tr>
<tr class="odd">
<td>TLB index</td>
<td>3</td>
</tr>
<tr class="even">
<td>TLB tag</td>
<td>3</td>
</tr>
<tr class="odd">
<td>TLB hit?</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>PPN</td>
<td>0x0D</td>
</tr>
<tr class="odd">
<td>Page fault?</td>
<td>No</td>
</tr>
</tbody>
</table>
<p>Physical address is <code>0x357</code></p>
<p>Physical memory reference</p>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Byte offset</td>
<td>3</td>
</tr>
<tr class="even">
<td>Cache index</td>
<td>5</td>
</tr>
<tr class="odd">
<td>Cache Tag</td>
<td>0x0D</td>
</tr>
<tr class="even">
<td>Cache hit?</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Cache byte returned</td>
<td>0x1D</td>
</tr>
</tbody>
</table>
<h2 id="case-study-the-intel-core-i7linux-memory-system"><span class="todo TODO">TODO</span> Case Study: The Intel Core i7/Linux Memory System</h2>
<h2 id="memory-mapping"><span class="todo TODO">TODO</span> Memory Mapping</h2>
<h2 id="dynamic-memory-allocation"><span class="todo TODO">TODO</span> Dynamic Memory Allocation</h2>
<h2 id="garbage-collection"><span class="todo TODO">TODO</span> Garbage Collection</h2>
<h2 id="common-memory-related-bugs-in-c-programs"><span class="todo TODO">TODO</span> Common Memory-Related Bugs in C Programs</h2>
<h2 id="summary"><span class="todo TODO">TODO</span> Summary</h2>
<h1 id="footnotes">Footnotes</h1>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Controller 集成在设备或主板上，Adapater 是主板上的插槽的可插拔设备<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>指令集( Instruction set artichecture ) 相当于对外的接口，CPU 具体实现可以不同，称为 microarchitecture<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>为什么不像 D1-Cache 直接作成 16 个元素的一维表？<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

			</div>
		</section>
	</body>
</html>
