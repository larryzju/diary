<!DOCTYPE html>
<html>
	<head>
		<title>docker.org</title>
		<link rel="stylesheet" href="/diary/_resources/css/main.css" />
		<script src="/diary/_resources/js/jquery-3.4.1.min.js"></script>
		<script src="/diary/_resources/js/swgen.js"></script>
	</head>
	<body>
		<nav id='content'>
		</nav>
		<section class="main-article-area">
			<div id='main'>
				<h2 id="complete-docker-course"><a href="https://www.youtube.com/watch?v=zIALD-U3pXM">Complete Docker Course!</a></h2>
<p>Hey everybody I have huge news for you. See that rocket ship going to Saturn? Yeah that's how big this news really is.</p>
<p>Docker is seriously awesome. It's my favorite most preferred way to package and deploy applications of any kind. If you've been following me on Twitter, you know that I really really like docker.</p>
<p>And you're like: dude I haven't been hearing that yeah you haven't because it's true. So I've been working on a way to help you get past the docker basics.</p>
<p>There are so many hello world application tutorials out there with docker. But it's hard to find good information to get you past those basics. So I've been making a course called real world docker.</p>
<p>See how that flew in? that was really cool. So I'm going to do it twice. Awesmoe!</p>
<p>And that guy there with the pen in the paper that illustrates that I've been working really hard on this course. Because I have it's a lot more work to put together a full course than to throw together a couple Hello World tutorials. So I've been doing it with O'Reilly Media. There're awesome they put out great stuff. They're those animal book people! Yeah! They really like animals. I think that's a goat or maybe it's a yak. I'm not really sure it might be a male sheep. But anyway they love their animals and they put out great web content if you're familiar with them again the course is called real world docker.</p>
<p>We've recently released it and it's going to be super cool. It's going to take you from feeling scared confused and alone from only knowing those docker basics that you see on those Hello World tutorials to not felling so scared so confused and so alone to get that confidence to actually deploy a docker application into production and then it's going to get you to the point of wow bring on the millions of users because I just scaled this application to handle massive traffic load and you get lots of code that's right lots of code. Any code that we use in any of the examples you get to take home and copy and paste and mess with and hack it's all yours.</p>
<p>So what will you actually learn well you're going to learn docker deployments. Everything from really simple single monolithic applications with continuous deployment that means you merge it to the master branch and it goes out to production merge it to the staging branch and it's on staging you're also going to learn how to brewk that app up into micro services which can scale much better in a large scenario and you're going to learn some of the deployment jeez that huge companies like Netflix use when they're deploying services across a large infrastructure. You're also going to learn networking and service discovery so you can swarm mupltiple servers together to act like on deployment platform when you can run apps on any one of those servers and everything just talks together just find and you'll also learn immutable and disponsable infrastructure which basically means you don't fix servers and apps when things go wrong you just destroy them and replace them and with continuous deployment you actually do it all the time it's a great way of deploying your application infrastructure. You're thinking wow, that's coll you're right! That's actually my next slide. It's so cool.</p>
<p>Thank you for bringing that up so. Again it's called real-world docker. The link is in the description and also you can go to O'Reilly comm and search for real-world docker it's also available on Safari Books if your company provides you with the Safari Books membership and so go check it out you're going to love the course it's going to help you out a ton and I give you information on how to contact me, So I'm available to help you out if you have any issues with that course. Enjoy and have a great day.</p>
<h2 id="learn-docker-in-12-minutes">Learn Docker in 12 Minutes</h2>
<p>Docker is a tool for running applications in an isolated environment.</p>
<p>It gives you advantages similar to running your application inside a virtual machine. Some of those advantages are your app always runs in exactly the same environment, so you don't get inconsistencies in how it behaves. If it works on your computer it works on every computer it works on the live server. It always acts the same.</p>
<p>If you're working on multiple projects it lets you sandbox each one and keep them separate good for security and eliminate a potential conflict between different projects.</p>
<p>And lastly it makes it easier to get going with somebody else's projects. you don't have to install all of the tools and dependencies that the project needs you just spin up the virtual machine put your call inside and it works.</p>
<p>Docker gives you these advantages but without the overhead and hassle of running and managing a virtual machine.</p>
<p>Instead we have containers. The code and the environment are all wrapped up inside a container. But a container is not a full virtual machine.</p>
<p>When you're going to virtual machine each machine gets its own full operating system including the kernel. The kernel is like the core of the operating system the bit that controls the low-level stuff. And this is quite resource heavy on the host machine the computer running the virtual machines.</p>
<p>Containers however they all use the host machines kernel a core bit of the operating system is shared but everything on top of that is still separated. Everything that makes a Linux distribution unique. Because all Linux distributions are born to Debian etc are all built on the same kernel and docker uses special features of the UNIX file system to create these isolated environments.</p>
<p>So containers are compromised the separation and sandbox is not quite as extreme, but it's enough and as a result a container can start up in seconds as opposed to minutes. They use fewer resources to take in a blessed disk space and using less memory.</p>
<p>So a container is a running instance of an image. An image is a template for creating the environment you wanted to snapshot of the system at a particular time. So it's got the operating system the software the application code all bundled up in a file.</p>
<p>Images are defined using a docker file. a dockerfile is just a text file with a list of steps to perform to create that image.</p>
<p>For example you to configure the operating system install the software you need copy the project files into the right places etc.</p>
<p>So you write a dockerfile then you build that and you get an image which you can then run to get containers. So let's try out this whole process.</p>
<p>First you're going to want to install docker for Mac or for Windows. Links are in the description this is just some software to allow docker containers to run on your computer. And unless you've got a specific reason to use it ignore docker toolbox that's the older way to run docker on a MAC or PC.</p>
<p>I've created a new folder just on my desktop for this demonstration and I'm going to write a super simple hello world application in PHP. It's literally just going to echo hello world.</p>
<p>And I'm going to save that in a folder called SRC for source as <code>index.php</code> right now you can't execute that file you need a web server our goal is to use docker to create one.</p>
<p>So let's make a new file and we're going to call this dockerfile. We're going to save it next to the source folder not inside docker file capital d one word and in here we're going to use cold to configure our environment so for this we want an operating system with PHP and Apache installed. Apache is the web server software.</p>
<p>The cool thing though is we don't have to start from scratch. We start in our docker file with the name of an existing image. An image that has already been built and then we build on top of that. Conveniently you can find lots of existing images on at the docker hub.</p>
<p>So if you go to <a href="http://hub.docker.com" class="uri">http://hub.docker.com</a>. Sign up the search doesn't seem to work if you logged out you can search for images. So we can search for a PHP image now the hub includes images from the whole community. So it's up to you to decide if the image is suitable and well-maintained the best ones to look out for are the official ones.</p>
<p>Luckily for us an official PHP image already exists, at the top you'll find all the variations of the image these are called tags.</p>
<p>So we just want to like the latest version of PHP and we want to apache it as well. So this line right here this has a few versions of PHP with Apache. Going left to right they get less specific so this will give you specifically 7.0.10.</p>
<p>All the way to the end where this will always just give you the latest version of PHP that one's usually a bad idea though. Because that means PHP could just unexpectedly be upgraded and a might break your old code. But one of these are the ones is fine for us now.</p>
<p>If you scroll down you even get instructions telling you how to use the image If you find the Apache section it tells you what to put in the dockerfile.</p>
<p>So we first want to define the base image using the from keyword. And we want then name of the image PHP then a colon and the name of the tag so we'll use as suggested 7.0-Apache. And then we want to copy our files inside the image using the <code>COPY</code> keyword so we want to copy the contents of source into <code>/var/www/html</code>.</p>
<p>There just telling us here that this is where Apache will look on its own file system and to find the file so we should put our files there. And you can see now why I called that folder source just so it matches these instructions.</p>
<p>We want one more thing in our doctor file we want to use the expose keyword to expose port 80. This just means when you run the image and you get a container that container will listen on port 80. By default it will just ignore all incoming requests.</p>
<p>If you're wondering what operating system this PHP image is based on. You can usually find the dockerfile that it's defined by. In this case it's linked next to the tag names. And we see it's based on Debian. Similarly that Debian image will have a dockerfile and they'll stack on top of each other like I said earlier. And this <strong>layering of images</strong> is a huge advantage of using docker.</p>
<p>The PHP dockerfile is a little bit more complicated than ours but let's just focus on ours for now.</p>
<p>So when we build our dockerfile. Docker is going to download PHP from the docker hub it's going to copy our files from source to this location inside of the image. It's going to tell running containers to listen on port 80. And then it's going to output a new image our new customized version which will be able to run.</p>
<p>So to build it I'm going to go to a terminal. First I'm going to move to the folder that it's in so we can see we've got docker file right there and I'm going to type <code>docker build -t</code> to give it a name.</p>
<p>I'm just going to call it hello world and then at the end you want to tell it the location of the dockerfile. And since it's in the current directory we just want to put &quot;.&quot; to say that.</p>
<p>Oops... helps if I save the docket file first.</p>
<p>The first time you do this it'll have to download all of the layers that make up that PHP image. Shouldn't take too long. Wanted to got the image it's going to copy our files inside. At the end is outputs our new image and it's going to be called hello world.</p>
<p>So we can run this by typing <code>docker run hello-world</code> there's one other thing we need in the middle of this we need to use the <code>-p</code> tag to forward a port port 80 from the host to port 80 in the container. So that means when a request gets the host the host is your computer when a request gets there docker is going to forward that to the container. And when it gets to the container that <code>expose</code> line that we've got in the docker file that will let the container accept the request and allow Apache to handle it.</p>
<p>So we can run that we'll get some output from the container from PHP. And then we can go to &quot;localhost&quot; and we'll see hello world. So we've done it we've got our application running inside a docker container.</p>
<p>Now if you go back to <code>index.php</code> and you change this. When you refresh localhost it won't change the the docker container won't reflect the new version of the file. And this is because when we built the image it made a copy of that file to see the change you'd need to rebuild the image and spin up a new container from the updated image.</p>
<p>During development this is obviously a massive pain and this is where volumes come in.</p>
<p>So there are two types of volumes want to persist and share data between containers we only have one container. I'm not going to talk about this today.</p>
<p>But the second type lets you share folders between the host and the container you can mount a local directory on your computer as a volume inside the container. Then the container when it's running we'll be able to see the files that were working on hit control-c to stop this container.</p>
<p>To mount a volume, we're going to add another option to the docker run command we're going to add <code>-v</code> and we want to tell it to mount the the folder <code>/users/jade/Desktop</code>. Tt needs to be the full path not a relative one <code>/docker/src</code> so we want that folder (that local folder) to be mounted to put a caller inside the container and <code>/var/www/html</code>.</p>
<p>So the image it copies this folder to this location inside the container but during development we don't just want to copy we want to see that folder we want a live view of that folder so we can mount it at that directory.</p>
<p>So this time when you run it you'll see changes that we make are reflected straight away as soon as we refresh. The docker container can't see that change in the file because it's looking at the file itself. So this is really useful during development but before you deploy this and try to run the image somewhere else you will need to rebuild the image to get an updated copy of the files put inside.</p>
<p>Volumes just give a running container the ability to see files on the host machines filesystem they do not change the image. So when you're done you can press ctrl-C to stop the container again.</p>
<p>So one last thing I want to mention. You can see we can easily stop a container manually by pressing ctrl-C but containers will stop by themselves when the main process exits. In this case that would only be if PHP died for some unexpected reason but you can equally make containers with short running tasks.</p>
<p>You might have a container which runs tests or a container which runs composer install. The process running in these containers will end when the task is complete. And when that main process ends the container will stop.</p>
<p>So for this reason you should endeavor to have one process per container because the life of that container is tied directly to a single process.</p>
<p>So you don't want 5 other things going on in the background that will all be brought down when without warning when the main process turn it and the ten it just stops.</p>
<p>But since containers are really lightweight you can run lots and lots of containers on your computer all at the same time and it's no problem at all.</p>
<p>So we found a suitable image as it uses a base image on the docker hub we wrote a dockerfile to orchestration that image and then we built that to output our new customized image which we could then run to get a container which would run our application. We mounted a volume using the <code>-v</code> tag and we ended up with a docker container running granters. It's a very simple application but it is that easy three line docker file gets this up and running.</p>
<p>In a future video we'll look at more complex situations and we'll look at orchestration options and deployment options so you can get your container to run a website on the Internet.</p>
<p>Please let me know how you fond this video. Feel free to ask any questions I'll try to answer as many as possible either in the comments or in a future video.</p>
<p>Thanks for watching. [[<a href="http://unknow.org" class="uri">http://unknow.org</a>][</p>
<h2 id="why-docker-is-the-perfect-fit-for-microservices">Why Docker is the Perfect Fit for Microservices</h2>
<p>To help you understand why docker and microservices often get talked about together as if they were the same thing.</p>
<p>I want to take a little bit to talk about why docker is the perfect fit for microservices. So let's start by looking at production and then local advantages.</p>
<p>First off, there's some production advantages that are huge.</p>
<p>One, containers can build very quickly and start nearly instantly.</p>
<p>Also you can create and scale services without adding more servers. Once your infrastructure is in place, all it takes to add a new service, simply run more containers across that infrastructure.</p>
<p>And containerized apps also make creating new or one-off environments very easy simply. Spin up some really dumb servers that have docker on that and run as many containers any versions of containers as you want. If you want to make an environment just for a specific test case, you can easily spin that environment up run things across it in that environment down.</p>
<p>You can also run a complete pseudo environment on your production infrastructure simply run different versions of different containers and link them all together.</p>
<p>Also provisioning new services is extremely simple.</p>
<p>As you've seen here's what a nodejs docker file tends to look like. That's about as complicated as it tends to get you may have five or ten more lines.</p>
<pre class="text"><code>FROM node:5.6.0

ENV DEBUG app:prod
ENV NODE_ENV production

# configure timezone
RUN echo &quot;America/Chicago&quot; &gt; /etc/timezone
RUN dpkg-reconfigure -f noninteractive tzdata

WORKDIR /app
ADD . /app

RUN npm install --production
RUN npm run webpack

EXPOSE 3000

CMD [&quot;npm&quot;, &quot;start&quot;]
</code></pre>
<p>But it's rarely any bigger than that if you're using a compiled language such as golang. It can actually get drastically simpler. Here's a golang dockerfile you start from scratch add your binary and run your binary. That's extremely simple and as you can imagine it builds very quickly.</p>
<pre class="text"><code>FROM scratch
ADD main /
CMD [&quot;/main&quot;]
</code></pre>
<p>And then here's one of the most complex ones. This would be a PHP nginx docker file and it's still really not that bad. 44 lines of code extremely simple to read and understand what's going on if you know server administration at all. And it's just easy to provision a complete image for running a PHP environment. So that's about as complicated as that gets.</p>
<pre class="text"><code>... (skip)
</code></pre>
<p>Let's look at some local development advantages.</p>
<p>First off it's very easy to run many services locally on your own local docker virtual machine. It's easy to run five 10, 50 or 100 services all at the same time.</p>
<p>Now if you wanted to do this with virtual machines such as vagrant or something like that. It doesn't really work very well for microservices. Because it's really hard and painful for your local development machine to run a hundred different things at once. You basically have to go one of two directions, you either under power your virtual machines so you can actually afford to run them all which gives you a really bad idea of how we'll all work when you're on production, or you have to adequately power those machines, leaving your local development machine highly taxed and possibly running very poorly</p>
<p>Where again with docker, simply it's easy to run many many services also running service. Dependencies is very seamless. Docker compose makes it easy for each service to require as fewer as many support services as it wants with no overhead.</p>
<p>As you can see, here's a dockerfile that has our web instance easily depending on Postgres and Redis. If the next service I work on doesn't require these I can easily stop all of these services and start the ones required to work on another service.</p>
<pre class="text"><code>version: &quot;2&quot;
services:
  web:
    depends_on:
  - postgres
  - redis
    image: mycompany/awesome-app
    ports:
  - 80:80
  postgres:
    image: postgres
    environment:
  - &quot;POSTGRES_PASSWORD=mypassword&quot;
  redis:
    image: redis
</code></pre>
<p>Also if I add any other services that were dependencies. That are maybe services my company owns. I could easily add five 10 or 50 supporting services to this docker compose file.</p>
<p>While good microservices design means you don't often have to run any supporting microservices, you're still capable and able to do it very simply.</p>
<p>You also have fewer boundaries when you're using docker with microservices. You can use multiple languages frameworks and databases for one. So you have a truly polyglot setup should you desire if you have an expensive computational service. You can use a more low-level language. Whereas if you have other services that don't require that low level power, you can use something more scripted. You can choose the correct language, the correct database, the correct framework for each piece of your application.</p>
<p>You can also connect multiple cloud providers to the same overlay Network. You could have AWS servers side-by-side with digital ocean servers. And it's not difficult to do, because overlay networking allows them all to communicate. You're really just not locked down as much having to have everything run in exactly the same place.</p>
<p>It's also really easy to run one-off support services. So you're building a microservice and it would really benefit from having Kafka running alongside of it. If you weren't running docker you'd have to provision a Kafka server, get Kafka up and running and then connect that to the service. You're building that wants to use whereas with the docker compose file as you saw earlier. It's simple just run cough cut and connect the two and then when you're ready for production just run a kafka container and connect the two. It's about the same way so there you have it.</p>
<p>There's some quick wins on why docker is really the perfect fit for microservices. There's a lot of production as well as local development advantages for it. And if you're doing microservices, it really should be your default tool of choice.</p>

			</div>
		</section>
	</body>
</html>
